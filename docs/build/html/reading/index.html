

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Reading Notes &mdash; Research Notes 0.1 文档</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="索引"
              href="../genindex.html"/>
        <link rel="search" title="搜索" href="../search.html"/>
    <link rel="top" title="Research Notes 0.1 文档" href="../index.html"/>
        <link rel="next" title="BlockChain Research" href="../blockchain/index.html"/>
        <link rel="prev" title="Notes Details" href="../competitions/details.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Research Notes
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../competitions/index.html">Competitions Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../competitions/details.html">Notes Details</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Reading Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#paper-list">Paper List</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#efficient-estimation-of-word-representations-in-vector-space">Efficient Estimation of Word Representations in Vector Space</a></li>
<li class="toctree-l3"><a class="reference internal" href="#on-availability-for-blockchain-based-systems">On Availability for Blockchain-Based Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="#personal-recommendation-using-deep-recurrent-neural-networks-in-netease">Personal Recommendation Using Deep Recurrent Neural Networks in NetEase</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../blockchain/index.html">BlockChain Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cryptology/index.html">Cryptology Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bmvc2018/index.html">BMVC 2018 Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../icassp2018/index.html">ICASSP 2018 Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../icpr2018/index.html">ICPR 2018 Notes</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Research Notes</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Reading Notes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/reading/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="reading-notes">
<h1>Reading Notes<a class="headerlink" href="#reading-notes" title="永久链接至标题">¶</a></h1>
<div class="section" id="paper-list">
<h2>Paper List<a class="headerlink" href="#paper-list" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><a class="reference internal" href="#efficient-estimation-of-word-representations-in-vector-space"><span class="std std-ref">Efficient Estimation of Word Representations in Vector Space</span></a> (NLP)</li>
<li><a class="reference internal" href="#on-availability-for-blockchain-based-systems"><span class="std std-ref">On Availability for Blockchain-Based Systems</span></a> (区块链)</li>
<li><a class="reference internal" href="#personal-recommendation-using-deep-recurrent-neural-networks-in-netease"><span class="std std-ref">Personal Recommendation Using Deep Recurrent Neural Networks in NetEase</span></a> (推荐系统)</li>
</ul>
<div class="section" id="efficient-estimation-of-word-representations-in-vector-space">
<span id="id1"></span><h3>Efficient Estimation of Word Representations in Vector Space<a class="headerlink" href="#efficient-estimation-of-word-representations-in-vector-space" title="永久链接至标题">¶</a></h3>
<p>传统方法解决NLP语法/语义问题的时候通常是没有考虑单词之间的相关性, 这样的话(1)对于语料库的质量要求比较高, 同时(2)在训练上通常用小于million级别的词库(limitation).</p>
<p>作者先回顾了传统的模型(NNLM和RNNLM), 其限制主要在于映射层到隐含层的计算复杂度大, 对此提出了CBOW和Skip-gram模型, 实验表明其计算复杂度和准确率都优于前者.</p>
<ul>
<li><p class="first">NNLM(Feedforward Neural Net Language Model)模型包含四层(输入层、映射层、隐含层、输出层), 其计算复杂度主要在 <strong>映射层</strong> 到 <strong>隐含层</strong> 之间的计算, 而且需要指定上下文的长度.</p>
<blockquote>
<div><blockquote>
<div><p><span class="math notranslate">\(Q=N\times D+N\times D\times H+H\times V\)</span></p>
</div></blockquote>
<p class="attribution">&mdash;&gt; <span class="math notranslate">\(Q=N\times D+N\times D\times H+H\times log_2{V}\)</span> (用平衡二叉树优化)</p>
</div></blockquote>
<blockquote>
<div><p>文中给出了一个参考, 当输入大小N=10的时候, 映射层大小 <span class="math notranslate">\(P(N\times D)\)</span> 通常取500-2000, 隐含层大小H通常取500-1000. 这样的话即使优化了输出的大小 <span class="math notranslate">\((V-&gt;log_2{V})\)</span> , 还是没有解决关键的地方</p>
</div></blockquote>
</li>
<li><p class="first">RNNLM(Recurrent Neural Net Language Model)模型被提出用来改进NNLM模型，<strong>去掉了映射层</strong> ，只有输入层、隐含层和输出层，计算复杂度来源于上一层的隐含层到下一层隐含层之间的计算.</p>
<blockquote>
<div><blockquote>
<div><p><span class="math notranslate">\(Q=H\times H+H\times V\)</span></p>
</div></blockquote>
<p class="attribution">&mdash;&gt; <span class="math notranslate">\(Q=H\times H+H\times log_2{V}\)</span> (用平衡二叉树优化)</p>
</div></blockquote>
</li>
</ul>
<p>作者提出了 <strong>CBOW</strong> (Continuous Bag-of-Words Model) 和 <strong>Skip-gram</strong> (Continuous Skip-gram Model) 模型, 其去掉了隐含层, 主要的计算复杂度依赖于softmax normalization.</p>
<blockquote>
<div><a class="reference internal" href="../_images/word2vec.png"><img alt="word2vec" class="align-middle" src="../_images/word2vec.png" style="width: 400px;" /></a></div></blockquote>
<ul>
<li><p class="first"><strong>CBOW</strong> : 与NNLM不同的是, 隐含层被移除了, 并且映射层会共享; 跟标准的词袋(bag-of-words)模型不同的是,该模型用连续的分布来代表上下文</p>
<blockquote>
<div><ul class="simple">
<li>计算复杂度为 <span class="math notranslate">\(Q = N \times D + D \times log_2{V}\)</span></li>
</ul>
</div></blockquote>
</li>
<li><p class="first"><strong>Skip-gram</strong> : 跟CBOW相似, 不过 <cite>It tries to maximize classification of a word based on another word in the sam sentence</cite>. 用单前的词输入到映射层的对数线性(log-linear)分类器中, 并预测给定范围的词(上下文)</p>
<blockquote>
<div><ul class="simple">
<li>计算复杂度为 <span class="math notranslate">\(Q = C \times (D + D \times log_2{V})\)</span></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>相比于传统的RNNLM和NNLM, 作者提出的两个模型去掉了隐含层, 因此计算复杂度降低了不少, 同时可以在更大的训练集上训练(billion级别). 实验结果表明在语法和语义任务上准确率大大提高</p>
<p><a class="reference internal" href="../_images/word2vec_result.png"><img alt="word2vec_result" class="align-middle" src="../_images/word2vec_result.png" style="width: 400px;" /></a></p>
<p>在训练时候作者是用 <cite>DistBelief</cite> 分布式框架, 速度有不少的提升(主要是计算复杂度降低了)</p>
<p><a class="reference internal" href="../_images/word2vec_train.png"><img alt="word2vec_train" class="align-middle" src="../_images/word2vec_train.png" style="width: 400px;" /></a></p>
<ul class="simple">
<li>作者训练的时候用了大量的CPU核心, 虽然比传统的模型可以训练维度更大的数据, 速度也更快. 考虑到现在的设备条件, 可以尝试用GPU加速训练.(已有人做过相关的工作)</li>
<li>值得注意一点的是, 作者是以单个词为单位的, 如果出现一些相关性强的短语(如 <cite>New York</cite> ), 可能表现就没那么好了, 对整体的准确率也有可能产生一定的影响. 在以后的工作中可以考虑一些类似的情况, 对数据进行预处理或者修改模型的结构.</li>
</ul>
</div>
<div class="section" id="on-availability-for-blockchain-based-systems">
<span id="id2"></span><h3>On Availability for Blockchain-Based Systems<a class="headerlink" href="#on-availability-for-blockchain-based-systems" title="永久链接至标题">¶</a></h3>
<p><cite>发表在SRDS 2017 (CCF B)</cite></p>
<p>偏分析性的一篇文章. 作者以 <a class="reference external" href="https://www.ethereum.org/">Ethereum</a> 为例, 在公链上收集了大量的交易数据, 用于分析在区块链中对交易最终确认时间(commit times)产生消极影响的原因, 最后提出了一个中断机制(中断/撤回交易), 以优化用户体验.</p>
<ul>
<li><p class="first">作者从Ethereum公链上收集了大量的交易(每次实验大概是 <span class="math notranslate">\(3\times 10^{5}\)</span> 个交易), 首先分析了 <cite>locktimes</cite> 和 <cite>maximum gas</cite>, 得到其不是 <cite>orphan</cite> 块产生的主要原因. 而最有可能对commit产生影响的是 <cite>network connectivity</cite> , <cite>gas price</cite> 和 <cite>gas limit</cite></p>
</li>
<li><p class="first">作者在三个场景中测试其中断(Abort)机制, 实验表明其提出的中断机制可以有效地(<span class="math notranslate">\(100\%\)</span>)中断这三种情况下的交易:</p>
<blockquote>
<div><ol class="arabic simple">
<li>A transaction does not get included in the usual period of time (交易被include的时间过长)</li>
<li>A client changes its mind and decides to roll-back the issued transaction (撤回交易)</li>
<li>A transaction is in indefinite pending state due to insufficient funds (资金不足导致交易陷入无限等待状态)</li>
</ol>
<ul>
<li><p class="first">在(1)中, 设定最长等待的时间为10分钟(根据前文的统计设定的), 提交了100个低于市场费率(<span class="math notranslate">\(mr, market\ rate\)</span>) (<span class="math notranslate">\(0, 0.1\times mr, \dots, 0.9\times mr\)</span>)的交易. 如果交易在10分钟内没有被包含的话, 那么就发送一个交易费率为 <span class="math notranslate">\(mr\)</span> , value为 <span class="math notranslate">\(0\)</span> 的交易到地址 0x0 (也就是空白交易).</p>
</li>
<li><p class="first">在(2)中, 跟场景(1)相似, 不过 <strong>最大容忍10分钟</strong> 改成了 <strong>等待3分钟后</strong> (模拟交易发起人在3分钟后想撤回交易)</p>
</li>
<li><p class="first">场景(3), 假设nonce 为 <span class="math notranslate">\(n\)</span> 时账户余额为 <span class="math notranslate">\(k\)</span> , 准备两个交易</p>
<blockquote>
<div><table border="1" class="docutils">
<colgroup>
<col width="48%" />
<col width="52%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math notranslate">\(Tx_1\)</span> (n+1)</th>
<th class="head"><span class="math notranslate">\(Tx_2\)</span> (n+2)</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><span class="math notranslate">\(\frac{1}{1000}k\)</span></td>
<td><span class="math notranslate">\(\frac{999}{1000}k\)</span></td>
</tr>
</tbody>
</table>
<p>先广播 <span class="math notranslate">\(Tx_2\)</span> , 5秒后广播 <span class="math notranslate">\(Tx_1\)</span>, 这样会因余额不足而导致死锁, 此时发送一个空白的、nonce为n+2的交易去中断 <span class="math notranslate">\(Tx_2\)</span>, 中断用时中位数为45秒</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">比特币中需要6个区块才能 <strong>最终确认</strong> 交易, 以太坊则需要12个区块(这个数字依赖于事物/交易的价值、挖矿的开销和攻击的威胁性), 这意味着攻击者难以控制足够的算力来破坏/改变当前的共识(<cite>51%攻击</cite>). 文中也提到一个使用少于51%的算力来攻击的工作. (对于区块链的攻击一般都是在网络层上的攻击, 基本没有对核心的加密算法的攻击.)</p>
</li>
<li><p class="first">两次时间的时间间隔有点大了(2016.11, 2017.04), 以太坊的交易可能会因为整体的网络情况而有所不同.</p>
</li>
<li><p class="first">可以模仿作者的思路在更多的网络上进行测试, 或者制定一个标准, 对比不同链的性能.</p>
</li>
<li><p class="first">实验中作者修改了最大连接的节点数为500(默认是25), 因此在实验时大都能连接到400个节点. 这在中断机制的实验中为作者的节点提供了有利的条件, 使得 <span class="math notranslate">\(T_{x_{abort}}\)</span> 更快地被广播. 因为以太坊出块的速度是相对稳定的, 这样子的话更容易实现中断. (但实际中默认是最大连接25个节点, 中断的成功率可能没实验中的效果这么好)</p>
</li>
</ul>
</div>
<div class="section" id="personal-recommendation-using-deep-recurrent-neural-networks-in-netease">
<span id="id3"></span><h3>Personal Recommendation Using Deep Recurrent Neural Networks in NetEase<a class="headerlink" href="#personal-recommendation-using-deep-recurrent-neural-networks-in-netease" title="永久链接至标题">¶</a></h3>
<p>本文提出一种用 <strong>DRNN</strong> (Deep Recurrent Neural Networks)和 <strong>FNN</strong> (Feedforward Neural Network) 来对用户网购的行为进行预测和实时推荐的方法. 该方法突破了传统的一些方法(如CF, 协同过滤)的限制, 可在线学习和实时训练, 并且准确率也大大提升.</p>
<p>对于传统的方法:</p>
<blockquote>
<div><ul class="simple">
<li>不能做到实时推荐的效果</li>
<li>准确率相对较低</li>
</ul>
</div></blockquote>
<p>Challenge:</p>
<blockquote>
<div><ul class="simple">
<li>输入向量大(用户可能访问多个页面)</li>
<li>模型需要对用户实时访问/顺序足够敏感和有效</li>
<li>模型需要在线学习, 速度要足够快</li>
</ul>
</div></blockquote>
<ul class="simple">
<li>在DRNN中, 因为用户访问的可能有多个网页, 因此把之前的/超出范围(n)的浏览记录合并成一个history state, 同时加上当前的一些浏览state作为输入. 其中history state合并为:</li>
</ul>
<div class="math notranslate">
\[\bar{V} = \sum_{i=0}^{x-n}\epsilon_{i}V_{i},\ \epsilon_{i}=\frac{\theta(p_i)}{\sum_{j=i}^{x-n}\theta(p_j)}\]</div>
<div class="line-block">
<div class="line">其中, <span class="math notranslate">\(V_i\)</span> 是页面 <span class="math notranslate">\(p_i\)</span> 的向量, <span class="math notranslate">\(\epsilon_{i}\)</span> 是旧状态的衰减因子</div>
</div>
<blockquote>
<div><ul class="simple">
<li><dl class="first docutils">
<dt>与标准的DRNN不同的是:</dt>
<dd><ul class="first last">
<li>模型是用来跟踪(<cite>track</cite>)用户的访问路径(用户到他所需产品的路径)</li>
<li>如果序列过长, 就把历史状态合并成一个 <cite>history state</cite>. 在计算量和准确率之间权衡.</li>
<li>用一个FNN模型来模型CF的工作, 对用户最终购买的产品进行预测</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<ul class="simple">
<li>FNN的作用跟传统的协同过滤相似, 根据用户的购买记录对用户的最终购买的产品进行预测</li>
</ul>
<div class="line-block">
<div class="line">最终, 两个模型合并输出最终的预测, 得到用户购买第 <span class="math notranslate">\(i\)</span> 个商品的概率为:</div>
</div>
<div class="math notranslate">
\[P(i)=\frac{f(\sum_{x=0}^{E-1}(w_{i}^{L_0}a_{L_{0}}(t)+b_{L_{0}}(t))+\sum_{x=0}^{\bar{E}-1}(\bar{w}_{i}^{L_1}\bar{a}_{x}^{(L_1)}+b_{x}^{(L_1)}))}
{\sum_{x}f(\sum_{x=0}^{E-1}(w_{i}^{L_0}a_{L_{0}}(t)+b_{L_{0}}(t))+\sum_{x=0}^{\bar{E}-1}(\bar{w}_{i}^{L_1}\bar{a}_{x}^{(L_1)}+b_{x}^{(L_1)}))}\]</div>
<ul class="simple">
<li>在实验中, 文中提到 <cite>Caffe 1.0</cite> 是没有RNN模型的, 所以通过 <cite>share weights</cite> 的方法将CNN转换成RNN. 文中给出了生成代码(<code class="docutils literal notranslate"><span class="pre">CodeGen(int</span> <span class="pre">w,</span> <span class="pre">int</span> <span class="pre">l,</span> <span class="pre">int</span> <span class="pre">h)</span></code>)的算法, 改算法可以根据输入的width, length 和 height来生成特定的RNN网络, 并结合遗传算法(<code class="docutils literal notranslate"><span class="pre">GenTune(int</span> <span class="pre">w,</span> <span class="pre">int</span> <span class="pre">l,</span> <span class="pre">int</span> <span class="pre">h)</span></code>)对其进行调参优化</li>
</ul>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../blockchain/index.html" class="btn btn-neutral float-right" title="BlockChain Research" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../competitions/details.html" class="btn btn-neutral" title="Notes Details" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Hatuw.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/translations.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>